{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38da96b2-d42f-46dc-b84b-f7afd79e1c38",
   "metadata": {},
   "source": [
    "To implement construction schedule optimisation using agentic RAG (Retrieval-Augmented Generation), ReAct (Retrieval-Augmented Controlled Transformation), and question answering (QA) capabilities with T5 in Python, we'll combine these techniques to effectively retrieve relevant information, generate optimised schedules, and answer specific queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ce10fd4-d968-4412-ba3a-788c455f3a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of T5ForQuestionAnswering were not initialized from the model checkpoint at t5-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import pipeline\n",
    "# Initialize T5 model and tokenizer\n",
    "model_name = 't5-base'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Initialise ReAct pipeline for retrieval\n",
    "react_pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Initialise QA pipeline for answering specific queries\n",
    "qa_pipeline = pipeline(\"question-answering\", model=model_name, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63ad004-d9c9-47a3-9b96-3e490f9ba6ca",
   "metadata": {},
   "source": [
    "### 1. Retrieve Schedule Information Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be024458-d695-4ce5-a95f-698b973778e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_schedule_information(task_name):\n",
    "    # Replace with your retrieval logic (database query, API call, etc.)\n",
    "    schedules = {\n",
    "        'foundation': \"Schedule for foundation construction: Day 1 - Excavation...\",\n",
    "        'framing': \"Schedule for framing: Day 1 - Laying out walls...\",\n",
    "        'roofing': \"Schedule for roofing: Day 1 - Installing trusses...\"\n",
    "    }\n",
    "    return schedules.get(task_name.lower(), \"Schedule information not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5435b310-79fc-4236-bf53-dd8df906e5ca",
   "metadata": {},
   "source": [
    "### 2. Agentic RAG Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1742132-b303-496a-a637-d4c9961cd728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agentic_rag(task_name):\n",
    "    # Retrieve relevant schedule information\n",
    "    schedule_info = retrieve_schedule_information(task_name)\n",
    "    \n",
    "    # Construct prompt for T5 based on retrieved information\n",
    "    prompt = f\"Document: {schedule_info}. Optimise construction schedule for {task_name}.\"\n",
    "    \n",
    "    # Generate optimized schedule using T5\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs, max_length=150, num_return_sequences=1, early_stopping=True)\n",
    "    optimized_schedule = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return optimized_schedule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc28d1a9-20f4-46d0-86aa-0cbb5b52d49f",
   "metadata": {},
   "source": [
    "### 3. ReAct Function for Document Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91394847-3aeb-4e13-8415-4a916c0c726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def react_retrieve(task_name):\n",
    "    # Example: Use ReAct to retrieve relevant documents\n",
    "    query = f\"Retrieve documents related to construction schedule optimization for {task_name}.\"\n",
    "    retrieved_docs = react_pipeline(query, max_new_tokens=100, num_return_sequences=1)\n",
    "    \n",
    "    # Extract and return the retrieved document\n",
    "    return retrieved_docs[0]['generated_text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b607abe3-c7c3-444f-b3c3-7a519e6c9783",
   "metadata": {},
   "source": [
    "### 4. Question Answering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53066617-9f09-4283-a485-c18387e8358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answer(task_name, question):\n",
    "    prin('Answer : ', 'Answer')\n",
    "    # Retrieve relevant schedule information\n",
    "    schedule_info = retrieve_schedule_information(task_name)\n",
    "    \n",
    "    # Concatenate schedule information with the question for QA\n",
    "    context = f\"Schedule for {task_name}: {schedule_info}\"\n",
    "    \n",
    "    # Perform question answering using T5\n",
    "    answer = qa_pipeline(question=question, context=context)\n",
    "    #prin('Answer : ', answer)\n",
    "    \n",
    "    return answer['answer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d926d175-6035-4c46-b5b6-b315c67ba397",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 16\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Example of agentic RAG for optimization\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#optimised_schedule = agentic_rag(task)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#print(f\"Optimised schedule for '{task}':\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Example of question answering\u001b[39;00m\n\u001b[1;32m     15\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the key tasks in the construction schedule for framing?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 16\u001b[0m answer \u001b[38;5;241m=\u001b[39m question_answer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframing\u001b[39m\u001b[38;5;124m\"\u001b[39m, question)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(answer)\n",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m, in \u001b[0;36mquestion_answer\u001b[0;34m(task_name, question)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquestion_answer\u001b[39m(task_name, question):\n\u001b[0;32m----> 2\u001b[0m     prin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnswer : \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnswer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Retrieve relevant schedule information\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     schedule_info \u001b[38;5;241m=\u001b[39m retrieve_schedule_information(task_name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prin' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    task = \"foundation\"\n",
    "    \n",
    "    # Example of agentic RAG for optimization\n",
    "    #optimised_schedule = agentic_rag(task)\n",
    "    #print(f\"Optimised schedule for '{task}':\")\n",
    "    #print(optimised_schedule)\n",
    "    \n",
    "    # Example of ReAct for document retrieval\n",
    "    #retrieved_doc = react_retrieve(task)\n",
    "    #print(f\"Retrieved document for '{task}':\")\n",
    "    #print(retrieved_doc)\n",
    "    \n",
    "    # Example of question answering\n",
    "    question = \"What are the key tasks in the construction schedule for framing?\"\n",
    "    answer = question_answer(\"framing\", question)\n",
    "    print(f\"Answer to '{question}':\")\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634122b9-0a00-4503-ac29-ad3dc0b0c3b2",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "    Retrieval: Adjust retrieve_schedule_information and react_retrieve functions based on your actual data retrieval needs (e.g., database queries, API calls).\n",
    "    Model Parameters: Tune max_length, num_return_sequences, and other parameters in model.generate() for optimal generation performance.\n",
    "    Error Handling: Implement robust error handling for production-level code.\n",
    "    Integration: Integrate these functions into your application or workflow as needed.\n",
    "\n",
    "This script provides a comprehensive approach to integrating agentic RAG, ReAct, and question answering capabilities with T5 for construction schedule optimization in Python. Adjust and expand upon it according to your specific requirements and use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3841f75f-3d38-4efb-a0bd-75465f687e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
