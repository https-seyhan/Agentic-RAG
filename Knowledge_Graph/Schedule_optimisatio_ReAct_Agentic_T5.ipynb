{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38da96b2-d42f-46dc-b84b-f7afd79e1c38",
   "metadata": {},
   "source": [
    "To implement construction schedule optimisation using agentic RAG (Retrieval-Augmented Generation), ReAct (Retrieval-Augmented Controlled Transformation), and question answering (QA) capabilities with T5 in Python, we'll combine these techniques to effectively retrieve relevant information, generate optimised schedules, and answer specific queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ce10fd4-d968-4412-ba3a-788c455f3a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of T5ForQuestionAnswering were not initialized from the model checkpoint at t5-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import pipeline\n",
    "# Initialize T5 model and tokenizer\n",
    "model_name = 't5-base'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Initialise ReAct pipeline for retrieval\n",
    "react_pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Initialize QA pipeline for answering specific queries\n",
    "qa_pipeline = pipeline(\"question-answering\", model=model_name, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63ad004-d9c9-47a3-9b96-3e490f9ba6ca",
   "metadata": {},
   "source": [
    "### 1. Retrieve Schedule Information Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be024458-d695-4ce5-a95f-698b973778e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_schedule_information(task_name):\n",
    "    # Example: Replace with your retrieval logic (database query, API call, etc.)\n",
    "    schedules = {\n",
    "        'foundation': \"Schedule for foundation construction: Day 1 - Excavation...\",\n",
    "        'framing': \"Schedule for framing: Day 1 - Laying out walls...\",\n",
    "        'roofing': \"Schedule for roofing: Day 1 - Installing trusses...\"\n",
    "    }\n",
    "    return schedules.get(task_name.lower(), \"Schedule information not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5435b310-79fc-4236-bf53-dd8df906e5ca",
   "metadata": {},
   "source": [
    "### 2. Agentic RAG Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1742132-b303-496a-a637-d4c9961cd728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agentic_rag(task_name):\n",
    "    # Retrieve relevant schedule information\n",
    "    schedule_info = retrieve_schedule_information(task_name)\n",
    "    \n",
    "    # Construct prompt for T5 based on retrieved information\n",
    "    prompt = f\"Document: {schedule_info}. Optimize construction schedule for {task_name}.\"\n",
    "    \n",
    "    # Generate optimized schedule using T5\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs, max_length=150, num_return_sequences=1, early_stopping=True)\n",
    "    optimized_schedule = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return optimized_schedule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc28d1a9-20f4-46d0-86aa-0cbb5b52d49f",
   "metadata": {},
   "source": [
    "### 3. ReAct Function for Document Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91394847-3aeb-4e13-8415-4a916c0c726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def react_retrieve(task_name):\n",
    "    # Example: Use ReAct to retrieve relevant documents\n",
    "    query = f\"Retrieve documents related to construction schedule optimization for {task_name}.\"\n",
    "    retrieved_docs = react_pipeline(query, max_new_tokens=100, num_return_sequences=1)\n",
    "    \n",
    "    # Extract and return the retrieved document\n",
    "    return retrieved_docs[0]['generated_text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b607abe3-c7c3-444f-b3c3-7a519e6c9783",
   "metadata": {},
   "source": [
    "### 4. Question Answering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53066617-9f09-4283-a485-c18387e8358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answer(task_name, question):\n",
    "    # Retrieve relevant schedule information\n",
    "    schedule_info = retrieve_schedule_information(task_name)\n",
    "    \n",
    "    # Concatenate schedule information with the question for QA\n",
    "    context = f\"Schedule for {task_name}: {schedule_info}\"\n",
    "    \n",
    "    # Perform question answering using T5\n",
    "    answer = qa_pipeline(question=question, context=context)\n",
    "    \n",
    "    return answer['answer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d926d175-6035-4c46-b5b6-b315c67ba397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saul/anaconda3/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized schedule for 'foundation':\n",
      "Optimize construction schedule for foundation construction: Day 1 - Excavation....\n",
      "Retrieved document for 'foundation':\n",
      "schedule optimization for foundation. Retrieve documents related to construction schedule optimization for foundation.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "None is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/saul/anaconda3/lib/python3.12/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/home/saul/anaconda3/lib/python3.12/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n           ^^^^^^^^^^^^^^^^\n  File \"/home/saul/anaconda3/lib/python3.12/site-packages/transformers/data/processors/squad.py\", line 242, in squad_convert_example_to_features\n    cls_index = span[\"input_ids\"].index(tokenizer.cls_token_id)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: None is not in list\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Example of question answering\u001b[39;00m\n\u001b[1;32m     15\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the key tasks in the construction schedule for framing?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 16\u001b[0m answer \u001b[38;5;241m=\u001b[39m question_answer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframing\u001b[39m\u001b[38;5;124m\"\u001b[39m, question)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(answer)\n",
      "Cell \u001b[0;32mIn[30], line 9\u001b[0m, in \u001b[0;36mquestion_answer\u001b[0;34m(task_name, question)\u001b[0m\n\u001b[1;32m      6\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSchedule for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mschedule_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Perform question answering using T5\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m answer \u001b[38;5;241m=\u001b[39m qa_pipeline(question\u001b[38;5;241m=\u001b[39mquestion, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m answer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/pipelines/question_answering.py:393\u001b[0m, in \u001b[0;36mQuestionAnsweringPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args_parser(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(examples, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(examples) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(examples[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(examples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/pipelines/base.py:1246\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[0;32m-> 1246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1248\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1249\u001b[0m                 [inputs], num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1250\u001b[0m             )\n\u001b[1;32m   1251\u001b[0m         )\n\u001b[1;32m   1252\u001b[0m     )\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:269\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 269\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:32\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_iter))\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:186\u001b[0m, in \u001b[0;36mPipelineChunkIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubiterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# Try to return next item\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubiterator)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# When a preprocess iterator ends, we can start lookig at the next item\u001b[39;00m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# ChunkIterator will keep feeding until ALL elements of iterator\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# Another way to look at it, is we're basically flattening lists of lists\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# into a single list, but with generators\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubiterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/pipelines/question_answering.py:412\u001b[0m, in \u001b[0;36mQuestionAnsweringPipeline.preprocess\u001b[0;34m(self, example, padding, doc_stride, max_question_len, max_seq_len)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`doc_stride` (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc_stride\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is larger than `max_seq_len` (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_seq_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mis_fast:\n\u001b[0;32m--> 412\u001b[0m     features \u001b[38;5;241m=\u001b[39m squad_convert_examples_to_features(\n\u001b[1;32m    413\u001b[0m         examples\u001b[38;5;241m=\u001b[39m[example],\n\u001b[1;32m    414\u001b[0m         tokenizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer,\n\u001b[1;32m    415\u001b[0m         max_seq_length\u001b[38;5;241m=\u001b[39mmax_seq_len,\n\u001b[1;32m    416\u001b[0m         doc_stride\u001b[38;5;241m=\u001b[39mdoc_stride,\n\u001b[1;32m    417\u001b[0m         max_query_length\u001b[38;5;241m=\u001b[39mmax_question_len,\n\u001b[1;32m    418\u001b[0m         padding_strategy\u001b[38;5;241m=\u001b[39mPaddingStrategy\u001b[38;5;241m.\u001b[39mMAX_LENGTH,\n\u001b[1;32m    419\u001b[0m         is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    420\u001b[0m         tqdm_enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    421\u001b[0m     )\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;66;03m# Define the side we want to truncate / pad and the text/pair sorting\u001b[39;00m\n\u001b[1;32m    424\u001b[0m     question_first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpadding_side \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/transformers/data/processors/squad.py:376\u001b[0m, in \u001b[0;36msquad_convert_examples_to_features\u001b[0;34m(examples, tokenizer, max_seq_length, doc_stride, max_query_length, is_training, padding_strategy, return_dataset, threads, tqdm_enabled)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(threads, initializer\u001b[38;5;241m=\u001b[39msquad_convert_example_to_features_init, initargs\u001b[38;5;241m=\u001b[39m(tokenizer,)) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[1;32m    368\u001b[0m     annotate_ \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m    369\u001b[0m         squad_convert_example_to_features,\n\u001b[1;32m    370\u001b[0m         max_seq_length\u001b[38;5;241m=\u001b[39mmax_seq_length,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m         is_training\u001b[38;5;241m=\u001b[39mis_training,\n\u001b[1;32m    375\u001b[0m     )\n\u001b[0;32m--> 376\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    377\u001b[0m         tqdm(\n\u001b[1;32m    378\u001b[0m             p\u001b[38;5;241m.\u001b[39mimap(annotate_, examples, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m),\n\u001b[1;32m    379\u001b[0m             total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(examples),\n\u001b[1;32m    380\u001b[0m             desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert squad examples to features\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    381\u001b[0m             disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m tqdm_enabled,\n\u001b[1;32m    382\u001b[0m         )\n\u001b[1;32m    383\u001b[0m     )\n\u001b[1;32m    385\u001b[0m new_features \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    386\u001b[0m unique_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000000000\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/tqdm/std.py:1169\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;66;03m# If the bar is disabled, then just walk the iterable\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;66;03m# (note: keep this check outside the loop for performance)\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable:\n\u001b[0;32m-> 1169\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/pool.py:423\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    415\u001b[0m result \u001b[38;5;241m=\u001b[39m IMapIterator(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_taskqueue\u001b[38;5;241m.\u001b[39mput(\n\u001b[1;32m    417\u001b[0m     (\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_guarded_task_generation(result\u001b[38;5;241m.\u001b[39m_job,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    421\u001b[0m         result\u001b[38;5;241m.\u001b[39m_set_length\n\u001b[1;32m    422\u001b[0m     ))\n\u001b[0;32m--> 423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (item \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m result \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m chunk)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/pool.py:873\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m--> 873\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[0;31mValueError\u001b[0m: None is not in list"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    task = \"foundation\"\n",
    "    \n",
    "    # Example of agentic RAG for optimization\n",
    "    optimized_schedule = agentic_rag(task)\n",
    "    print(f\"Optimized schedule for '{task}':\")\n",
    "    print(optimized_schedule)\n",
    "    \n",
    "    # Example of ReAct for document retrieval\n",
    "    retrieved_doc = react_retrieve(task)\n",
    "    print(f\"Retrieved document for '{task}':\")\n",
    "    print(retrieved_doc)\n",
    "    \n",
    "    # Example of question answering\n",
    "    question = \"What are the key tasks in the construction schedule for framing?\"\n",
    "    answer = question_answer(\"framing\", question)\n",
    "    print(f\"Answer to '{question}':\")\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634122b9-0a00-4503-ac29-ad3dc0b0c3b2",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "    Retrieval: Adjust retrieve_schedule_information and react_retrieve functions based on your actual data retrieval needs (e.g., database queries, API calls).\n",
    "    Model Parameters: Tune max_length, num_return_sequences, and other parameters in model.generate() for optimal generation performance.\n",
    "    Error Handling: Implement robust error handling for production-level code.\n",
    "    Integration: Integrate these functions into your application or workflow as needed.\n",
    "\n",
    "This script provides a comprehensive approach to integrating agentic RAG, ReAct, and question answering capabilities with T5 for construction schedule optimization in Python. Adjust and expand upon it according to your specific requirements and use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3841f75f-3d38-4efb-a0bd-75465f687e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
